---
title: "Analysis for Motor Trend"
author: "Daniel Hertenstein"
date: "January 13, 2017"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary

## Exploratory Analysis

```{r}
head(mtcars)
dim(mtcars)
```

The mtcars data set contains observations of 11 variables for 32 cars extracted from the 1974 Motor Trend US Magazine. The variables are, in order as seen by the first 5 rows: miles per gallon (mpg), number of cylinders, engine displacement, gross horsepower, rear axle ratio, weight (in tons (1000 lbs)), 1/4 mile time, V/S, transmission type, number of forward gears, and number of carburetors. Our analysis explores mpg for cars with manual vs. automatic transmissions. To get an idea of the distribution of mpg for each category, we start with a simple violin plot.

```{r}
library(ggplot2)
ggplot(mtcars, aes(factor(am), mpg)) + geom_violin() + labs(x="Automatic (0) vs. Manual (1)", title="Naively, Manual Looks Better")
```

Based on this plot, we can make a naive and weak claim that cars with manual transmissions have higher mpgs than those with automatic transmission. However, there may be other reasons for the difference in this plot due to differences in the other variables in the data set such as weight or number of cylinders. To address this, we will fit a linear model relating mpg to the most important (to the best of our abilities) factors.

## Model Selection

### Linear, Binary, or Poisson?

Binary General Linear Models (GLM)s are meant to model outcomes that can take only two values. Poisson GLMs are meant to model outcomes that take the form of a count over a timespan (ex. number of visitors to hospital each hour). Since our outcome, miles per gallon for a car, is neither, we should use a standard multivariable linear regression. Our data have 10 possible factors to include as variables, and so we must decide which of these to include in our model.

### Which other factors to include

```{r}
fit <- lm(mpg ~ am, mtcars)
summary(fit)
par(mfrow = c(2, 2))
plot(fit)
```

```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
   usr <- par("usr"); on.exit(par(usr))
   par(usr = c(0, 1, 0, 1))
   r <- abs(cor(x, y))
   txt <- format(c(r, 0.123456789), digits = digits)[1]
   txt <- paste0(prefix, txt)
   if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
   text(0.5, 0.5, txt)
}
pairs(mtcars, upper.panel = function(x,y){points(x,y) + abline(lm(y~x), col='red')}, lower.panel = panel.cor)
```

The pairs plot can give us an idea of what variables may be important and what other variables may be correlated (and confound our fit).

```{r}
fit_all <- lm(mpg ~ ., mtcars)
summary(fit_all)
par(mfrow = c(2,2))
plot(fit_all)
```

The t-values in this summary (including all variables in our model) say that we cannot reject the hypothesis that the correlation is 0.

```{r}
fit <- lm(mpg ~ wt * factor(am), mtcars)
g <- ggplot(mtcars, aes(x=wt, y=mpg, color=factor(am)))
g <- g + geom_point(size=6, color='black') + geom_point(size=4)
g1 <- g
g1 <- g1 + geom_abline(intercept = coef(fit)[1], slope=coef(fit)[2], size=2)
g1 <- g1 + geom_abline(intercept = coef(fit)[1] + coef(fit)[3], slope = coef(fit)[2] + coef(fit)[4], size=2)
g1
```

This model and then plot show that heavier cars have lower mpg and that whether manual or automatic is better depends on the weight of the car, but there isn't much overlap in weight between automatic and manual cars, so it's hard to say if this is really true.

fit_w_weight <- lm(mpg ~ am + wt, mtcars)
fit3 <- lm(mpg ~ am + wt + hp, mtcars)
anova(fit, fit_w_weight, fit3)

#### Include some residual plots

Do the plot(fit) here of the final model

## Automatic vs. Manual

### Hypothesis Testing

### Quantifying the Uncertainty

## Conclusions and Assumptions?